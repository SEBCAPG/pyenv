{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "deep_env",
      "language": "python",
      "name": "deep_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEBCAPG/pyenv/blob/master/Light_tensorflow_08_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8bYAsAdYjNE"
      },
      "source": [
        "\n",
        "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height:150px\">\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<h1 style = \"text-align:center\" > Introduction à TensorFlow </h1>\n",
        "<h2 style = \"text-align:center\" > Transfer Learning </h2>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "Ce notebook est destiné à pratiquer les notions évoquées dans le dernier exercice du module sur une machine plus adaptée.\n",
        "\n",
        "Si c'est la première fois que vous utilisez colab, n'hésitez pas à jeter un coup d'oeil sur ce [notebook](https://colab.research.google.com/drive/1jXEKOk3mRYBqFWoVwJ0ZpsRJCWj46Yxt?usp=sharing).\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<h2 style = \"text-align:center\" > 1. Traitement des données </h2>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "> Le jeu de données sur lequel nous allons travailler est constitué d'images de radiographie contenant quatre classes : **glioma tumor**, **meningioma tumor**, **no tumor**, **pituitary tumor**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcChsXyHbJbr"
      },
      "source": [
        "!wget https://assets-datascientest.s3.eu-west-1.amazonaws.com/datasets/transferLearning_TensorFlow_brains.zip\n",
        "!unzip transferLearning_TensorFlow_brains.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u0UBqWfrDXt"
      },
      "source": [
        "Un des interêts principaux de colab est la mise à disposition d'un GPU. Utiliser un GPU permet d'accelerer grandement l'execution et donc l'entrainement de modèle de deep learning. Pour configurer le GPU (processeur graphique), il suffit de cliquer sur Edit > Notebook settings et sélectionner GPU comme accélérateur matériel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWItJiHequHn"
      },
      "source": [
        "* Exécuter la cellule suivante pour vérifier que le GPU soit bien activé."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z31ZjmjqtXC"
      },
      "source": [
        "import tensorflow as tf \n",
        "if tf.test.gpu_device_name(): \n",
        "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please change your hardware accelerator\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_sFPcyRboOp"
      },
      "source": [
        "* Exécuter la cellule suivant permettant de créer un dataframe df contenant le chemin vers l'image et la classe correspondante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG5yn0r3YjNI"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "# Trouver tous les chemins vers les fichiers qui finissent par .jpg\n",
        "liste = glob.glob('./Training/*/*.jpg')\n",
        "# Remplacer les \\\\ par /\n",
        "liste = list(map(lambda x : [x, x.split('/')[2]], liste))\n",
        "# Créer un DataFrame pandas\n",
        "df = pd.DataFrame(liste, columns=['filepath', 'nameLabel'])\n",
        "df['label'] = df['nameLabel'].replace(df.nameLabel.unique(), [*range(len(df.nameLabel.unique()))])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--SptL2CYjNL"
      },
      "source": [
        "\n",
        "\n",
        "* (d) Redimensionner l'image chargée précédemment en (256, 256)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtYwfG2eYjNM"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd0-nAV7YjNM",
        "scrolled": true,
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "# Chemin de l'image\n",
        "filepath = df.filepath[0]\n",
        "# Lecture du fichier\n",
        "im = tf.io.read_file(filepath)\n",
        "# On décode le fichier\n",
        "im = tf.image.decode_jpeg(im, channels=3)\n",
        "# Redimensionnement \n",
        "tf.image.resize(im, size=(256,256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDgqj4-3YjNM"
      },
      "source": [
        "## Charger le jeu de données\n",
        "\n",
        "\n",
        "\n",
        "* (e) Séparer le jeu de données **`df.filepath`** et la variable cible **`df.label`** en un ensemble d'entraînement **X_train_path**, **y_train**, et en un ensemble de test **X_test_path**, **y_test**. Nous choisirons un rapport de 80% pour les données d'entraînements et une graine aléatoire 1234.\n",
        "\n",
        "\n",
        "* (f) Charger les images de **X_test_path** redimensionnées à [256,256,3] en mémoire dans la variable **X_test**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9G-Hfc-YjNN"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmd4HjIBYjNO",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "X_train_path, X_test_path, y_train, y_test = train_test_split(df.filepath, df.label, train_size=0.8, random_state=456)\n",
        "\n",
        "X_test = []\n",
        "for filepath in tqdm(X_test_path):\n",
        "    # Lecture du fichier\n",
        "    im = tf.io.read_file(filepath)\n",
        "    # On décode le fichier\n",
        "    im = tf.image.decode_jpeg(im, channels=3)\n",
        "    # Redimensionnement\n",
        "    im = tf.image.resize(im, size=(256, 256))\n",
        "    X_test.append([im])\n",
        "    \n",
        "X_test = tf.concat(X_test, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvYZWhJQYjNO"
      },
      "source": [
        "> Maintenant que les données de test sont chargées, il est nécessaire de définir un **dataset** permettant de charger les images à chaque itération du modèle. <br>\n",
        "\n",
        "* (g) Définir une fonction `load_image` avec comme argument `filepath` retournant une image redimensionnée en (256, 256).\n",
        "\n",
        "\n",
        "* (h) Définir un dataset **`dataset_train`** de **`(X_train_path, y_train)`** à l'aide de la fonction `from_tensor_slices`.\n",
        "\n",
        "\n",
        "* (i) Appliquer la fonction `load_image` à chaque valeur de **X_train_path** à l'aide de la méthode `map`. Pour que le chargement s'effectue en multi-tasking, préciser l'argument `num_parallel_calls = -1`.\n",
        "\n",
        "\n",
        "* (j) Regrouper les observations sous forme de batchs de taille 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddB0Q61NYjNP"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v4qAFMpYjNP",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "@tf.function\n",
        "def load_image(filepath, resize=(256, 256)):\n",
        "    im = tf.io.read_file(filepath)\n",
        "    im = tf.image.decode_png(im, channels=3)\n",
        "    return tf.image.resize(im, resize)\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
        "\n",
        "dataset_train = dataset_train.map(lambda x, y : [load_image(x), y], num_parallel_calls=-1).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vShmXGfBYjNQ"
      },
      "source": [
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<h2 style = \"text-align:center\" > 2. Définition et entraînement d'un modèle </h2>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "> Les modèles de classification d'image ou de détection d'objet utilisent généralement une approche par transfer Learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlZrtVE8YjNR"
      },
      "source": [
        "\n",
        "\n",
        "* (a) Charger le modèle `EfficientNetB1` de **`tensorflow.keras.applications`** sous le nom **`efficientNet`**. La partie classification ne sera pas prise et l'`input_shape` sera (256, 256, 3).\n",
        "\n",
        "\n",
        "* (b) Freezer les poids du modèle.\n",
        "\n",
        "\n",
        "* (c) Afficher le résumé du modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UheNJnaYjNR"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW6IC0ukYjNR",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "\n",
        "# Chargement du modèle efficientNet\n",
        "efficientNet = EfficientNetB1(include_top=False, input_shape=(256,256,3))\n",
        "\n",
        "# Bloquage du blackbone\n",
        "for layer in efficientNet.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "efficientNet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoIKKjBoYjNR"
      },
      "source": [
        "### Partie Classification\n",
        "\n",
        "* (d) Ajouter le modèle pré-entraîné à un objet `Sequential` qui portera le nom de **model**.\n",
        "\n",
        "\n",
        "* (e) Ajouter à ce modèle une couche `GlobalAveragePooling2D`.\n",
        "\n",
        "\n",
        "* (f) Ajouter quelques couches `Dense` et `Dropout` au modèle.\n",
        "\n",
        "\n",
        "* (g) Finir par une couche `Dense` avec 4 neurones et une fonction d'activation 'softmax'.\n",
        "\n",
        "\n",
        "* (h) Afficher le résumé du modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzY0oi_VYjNS"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38z9P318YjNS",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(efficientNet)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYYS_AOBYjNT"
      },
      "source": [
        "* (i) Compiler le modèle avec une fonction de perte `sparse_categorical_crossentropy`, un optimizer `'adam'` et une métrique `['accuracy']`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9nW62YlYjNT"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx9UOdNUYjNT",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCWKAa8mYjNT"
      },
      "source": [
        "## Entraînement du modèle\n",
        "\n",
        "\n",
        "* (j) Entraîner le modèle à l'aide la méthode `fit` sur 10 epochs en ajoutant les callbacks suivants :\n",
        "    * Une sauvegarde des poids à chaque epoch.\n",
        "    \n",
        "    * Une diminution du taux d'apprentissage si la métrique de validation ne s'améliore pas dans les 5 dernières epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsUwBjlcYjNT"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z_Z4zghcYjNT",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "# Savegarde automatique des poids\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath='checkpoint', \n",
        "                                       monitor='val_loss',\n",
        "                                       save_best_only=True,\n",
        "                                       save_weights_only=False,\n",
        "                                       mode='min',\n",
        "                                       save_freq='epoch')\n",
        "\n",
        "# Réduction automatique du taux d'apprentissage\n",
        "lr_plateau = callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                         patience=5,\n",
        "                                         factor=0.1,\n",
        "                                         verbose=2,\n",
        "                                         mode='min')\n",
        "\n",
        "model.fit(dataset_train, epochs=10, validation_data=(X_test, y_test), callbacks=[lr_plateau, checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cfqZgfeYjNU"
      },
      "source": [
        "$\\DeclareMathOperator*{\\argmax}{argmax}$\n",
        "\n",
        "## Évaluation\n",
        "\n",
        "* (k) Prédire la probabilité des classes du jeu de données **X_test**.\n",
        "\n",
        "\n",
        "* (l) Prédire dans **y_pred** la classe la plus probable à l'aide de la fonction `argmax` de **`tensorflow`** en précisant `axis=-1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVLQ1nidYjNU"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl3mnaPYYjNU",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "# Probabilités renvoyées par le modèle\n",
        "y_prob = model.predict(X_test, batch_size=64)\n",
        "\n",
        "# Prédiction de la classe\n",
        "y_pred = tf.argmax(y_prob, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YohmsH7bYjNU"
      },
      "source": [
        "* (m) Afficher le score de précision à l'aide de la fonction `accuracy_score` de **`sklearn.metrics`**.\n",
        "\n",
        "\n",
        "* (n) Afficher la matrice de confusion à l'aide de la fonction `confusion_matrix` de **`sklearn.metrics`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT0qVAFjYjNV"
      },
      "source": [
        "## Insérez votre code ici\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu43oXQIYjNV",
        "cellView": "form"
      },
      "source": [
        "#@title Solution\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('Accuracy :', accuracy_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4q41-QdYjNV"
      },
      "source": [
        "* (o) Exécuter la cellule suivante pour afficher les prédictions de notre modèle sur 3 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXKFgP7JYjNV"
      },
      "source": [
        "indices_random = tf.random.uniform([3], 0, len(X_test), dtype=tf.int32)\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "for i, idx in enumerate(indices_random):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(tf.cast(X_test[idx], tf.int32))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title('Pred class : {} \\n Real class : {}'.format(df.nameLabel.unique()[y_pred[idx]], df.nameLabel.unique()[y_test.values[idx]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVBxUoRzYjNV"
      },
      "source": [
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<h2 style = \"text-align:center\" > Ce qu'il faut retenir de ce module </h2> \n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "\n",
        "## Méthodologie\n",
        "\n",
        "> Globalement, la méthodologie pour résoudre un problème à l'aide d'outils de deep learning est la suivante :\n",
        ">\n",
        ">1. Définir un **dataset** permettant de mettre en forme les données et de partitionner en batchs.\n",
        ">\n",
        ">\n",
        ">2. Construire un modèle : MLP, CNN, RNN, transfer learning ...\n",
        ">\n",
        ">\n",
        ">3. Compiler le modèle : définition d'une fonction de perte, métrique, optimizer.\n",
        ">\n",
        ">\n",
        ">4. Entraîner le modèle. Il y'a deux manières équivalentes de le faire:\n",
        ">    - Méthode **`fit`** : problème simple.\n",
        ">    - Calculer le gradient de la fonction de coût puis rétropropager l'erreur : problème complexe.\n",
        ">    \n",
        ">   \n",
        ">5. Prédiction et évaluation du modèle.\n",
        "\n",
        "\n",
        "\n",
        "## Dataset\n",
        "\n",
        "> TensorFlow possède un sous ensemble **`tensorflow.data.dataset`**  qui permet d'appliquer toutes les étapes de pré-processing sur les données. C'est un pipeline d'opérations appliquées sur les entrées. Un exemple :\n",
        ">\n",
        "> * Charger les images + redimensionner (en parallélisant les calculs).\n",
        ">\n",
        ">\n",
        "> * Appliquer des méthodes d'augmentation de données.\n",
        ">\n",
        ">\n",
        "> * Normaliser les données.\n",
        ">\n",
        ">\n",
        "> * Regrouper les données en lots.\n",
        "\n",
        "\n",
        "\n",
        "## Keras\n",
        "\n",
        "> La version de TensorFlow 2.0+ a été construite autour du framework [**keras**](https://www.tensorflow.org/guide/keras).\n",
        ">\n",
        "> Vous pouvez retrouver toutes les fonctionnalités de **keras** dans **`tensorflow.keras`**. Il y'a notamment :\n",
        ">\n",
        ">* Les couches de neurones dans **`tensorflow.keras.layers`**. Il est possible de créer des couches personnalisées en faisant hériter la classe de la couche avec **`tensorflow.keras.layers.Layer`**.\n",
        ">\n",
        ">\n",
        ">* Les modèles pré-entrainés dans  **`tensorflow.keras.applications`**.\n",
        ">\n",
        ">\n",
        ">* Les fonctions de pertes dans **`tensorflow.keras.losses`**\n",
        ">\n",
        ">\n",
        ">* Les métriques dans **`tensorflow.keras.metrics`**.\n",
        ">\n",
        ">\n",
        ">* Les optimizers dans **`tensorflow.keras.optimizers`**.\n",
        "\n",
        "## Callbacks\n",
        "\n",
        "\n",
        "> Les rappels (***callbacks***) sont des outils qui permettent de contrôler l'entraînement et évaluation d'un modèle. Il est alors possible de connaître l'état interne d'un modèle, de le sauvegarder, d'afficher des statistiques intéressantes et même de changer des hyperparamètres pendant les étapes de l'entraînement.\n",
        ">\n",
        "> Les callbacks suivants peuvent être très pratique en Deep Learning :\n",
        ">\n",
        "> * Sauvegarder les meilleurs poids du modèle au cours de l'entraînement :\n",
        ">\n",
        ">```python\n",
        ">callbacks.ModelCheckpoint(filepath=filepath, \n",
        ">                           monitor='val_loss',\n",
        ">                           save_best_only=True,\n",
        ">                           save_weights_only=False,\n",
        ">                           mode='min',\n",
        ">                           save_freq='epoch')\n",
        ">\n",
        ">```\n",
        ">\n",
        "> * Réduire automatiquement le learning rate :\n",
        ">\n",
        ">```python\n",
        ">callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        ">                             patience=5,\n",
        ">                             factor=0.5,\n",
        ">                             verbose=2,\n",
        ">                             mode='min')\n",
        ">```\n",
        ">\n",
        "> * Arrêter l'entraînement si le modèle n'évolue plus (très pratique pour ne pas gérer le nombre d'epoch) :\n",
        ">\n",
        ">```python\n",
        ">callbacks.EarlyStopping(monitor='val_loss',\n",
        ">                         patience=8,\n",
        ">                         mode='min',\n",
        ">                         restore_best_weights=True)\n",
        ">```"
      ]
    }
  ]
}